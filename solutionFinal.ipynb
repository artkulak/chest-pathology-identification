{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "import gc\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# ML Imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend as K\n",
    "import keras.layers as L\n",
    "\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "PATH = ''\n",
    "IMAGE_PATH = 'chestImagesBiClass/'\n",
    "RND_SEED = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting CNN Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Building separate models to extract decaf features from the intermidiate layer of VGG19\n",
    "def build_decaf(net, i):\n",
    "    decaf = Model(inputs=net.input,outputs=net.layers[i].output)\n",
    "    return decaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model for feature extraction\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "model = Sequential()\n",
    "model.add(L.Conv2D(32, (3, 3), input_shape=input_shape, activation = 'relu'))\n",
    "model.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(L.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(L.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(256, activation = 'relu'))\n",
    "model.add(L.Dense(128, activation = 'relu'))\n",
    "model.add(L.Dense(32, activation = 'relu'))\n",
    "model.add(L.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac201cac52f3402bbc3c1eba0a699974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1341), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d1ac141b214d45880d6dd3ef3e34b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Extract data and labels from 2 file folders\n",
    "image_paths = []\n",
    "for img in tqdm_notebook(os.listdir(IMAGE_PATH + 'NORMAL/')):\n",
    "    image_paths.append(IMAGE_PATH + 'NORMAL/' + img)\n",
    "    im = cv2.imread(IMAGE_PATH + 'NORMAL/' + img)\n",
    "    im = cv2.resize(im, (224, 224)).reshape(224, 224, 3)\n",
    "    images.append(im)\n",
    "    labels.append(0)\n",
    "    \n",
    "for img in tqdm_notebook(os.listdir(IMAGE_PATH + 'PNEUMONIA/')):\n",
    "    if np.random.rand() < 0.3:\n",
    "        image_paths.append(IMAGE_PATH + 'PNEUMONIA/' + img)\n",
    "        im = cv2.imread(IMAGE_PATH + 'PNEUMONIA/' + img)\n",
    "        im = cv2.resize(im, (224, 224)).reshape(224, 224, 3)\n",
    "        images.append(im)\n",
    "        labels.append(1)\n",
    "images = np.asarray(images) / 255.\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss: 0.5237 - acc: 0.7540\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.2297 - acc: 0.9152\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.1797 - acc: 0.9333\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.1215 - acc: 0.9562\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.1005 - acc: 0.9630\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.0713 - acc: 0.9767\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.0805 - acc: 0.9715\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.0565 - acc: 0.9815\n",
      "Epoch 9/10\n",
      " - 7s - loss: 0.0618 - acc: 0.9791\n",
      "Epoch 10/10\n",
      " - 7s - loss: 0.0532 - acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2db02c9940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the feature extracting CNN\n",
    "model.fit(images, labels, batch_size = 32, epochs = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separate model for each of the Dense layers, to extract intermidiate layer information\n",
    "decaf5 = build_decaf(model, -4)\n",
    "decaf6 = build_decaf(model, -3)\n",
    "decaf7 = build_decaf(model, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284f4fc95def4d90894cc2b7f79cbb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2488), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting decaf5, decaf6, decaf7 features from the intermidiate layers\n",
    "imageFeatures = []\n",
    "for img in tqdm_notebook(image_paths):\n",
    "    im = cv2.imread(img) \n",
    "    im = cv2.resize(im, (224, 224)).reshape(1, 224, 224, 3) / 255.\n",
    "    decaf5_out=decaf5.predict(im)\n",
    "    decaf6_out=decaf6.predict(im)\n",
    "    decaf7_out=decaf7.predict(im)\n",
    "\n",
    "    decafFeatures = np.concatenate([decaf5_out, decaf6_out, decaf7_out], axis = 1)\n",
    "    imageFeatures.append(decafFeatures)\n",
    "    \n",
    "    \n",
    "imageFeatures = np.asarray(imageFeatures)\n",
    "imageFeatures = np.squeeze(imageFeatures, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting GIST Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f956f91f25a47e4a27dd8304fd9f0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2488), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matlab\n",
    "from matlab import engine\n",
    "gistFeatures = []\n",
    "eng = matlab.engine.start_matlab()\n",
    "\n",
    "# Extractring GIST features from images\n",
    "for img in tqdm_notebook(image_paths):\n",
    "    im = cv2.imread(img)\n",
    "    im = cv2.resize(im, (64, 64)) / 255\n",
    "    im =  matlab.double(im.tolist())\n",
    "    gist = list(eng.extract_gist(im)[0])\n",
    "    gistFeatures.append(gist)\n",
    "    \n",
    "gistFeatures = np.asarray(gistFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting BOVW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "extractor = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "def features(image, extractor):\n",
    "    keypoints, descriptors = extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27232e92f6954d2bbdb15287fb491286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2488), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDescriptors = np.array([])\n",
    "\n",
    "# Extracting SIFT features from each image\n",
    "for img in tqdm_notebook(image_paths):\n",
    "    im = cv2.imread(img)\n",
    "    im = cv2.resize(im, (224, 224))\n",
    "    keypoints, descriptors = features(im, extractor)\n",
    "    if allDescriptors.shape[0] == 0:\n",
    "        allDescriptors = descriptors\n",
    "    else:\n",
    "        allDescriptors = np.concatenate([allDescriptors, descriptors], axis = 0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931a5fa13adc4e49ad3fa4e3172c50ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "nFeatures = 500\n",
    "km = KMeans(n_clusters = nFeatures)\n",
    "km.fit(allDescriptors[:10000])\n",
    "bovwFeatures = np.zeros((labels.shape[0], nFeatures))\n",
    "\n",
    "# Combining all SIFT features into the dataset and fitting KMeans clustering to extract 1000 clusters, after that\n",
    "# making a histogram for each image - which is are the gist features\n",
    "\n",
    "for index, img in tqdm_notebook(enumerate(image_paths)):\n",
    "    im = cv2.imread(img)\n",
    "    im = cv2.resize(im, (224, 224))\n",
    "    keypoints, descriptors = features(im, extractor)\n",
    "    \n",
    "    LABELS = km.predict(descriptors)\n",
    "    for lab in LABELS:\n",
    "        bovwFeatures[index, lab] += 1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using Kruskal-Wallis non parametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Concatenating all the features from previous steps\n",
    "finalFeatures = np.concatenate([imageFeatures, gistFeatures, bovwFeatures], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Selecting best k features using Kruskal-Wallis (ANOVA) test\n",
    "selector = SelectKBest(f_classif, k=500)\n",
    "\n",
    "selectedFeatures = selector.fit_transform(finalFeatures, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label prediction and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting and predicting using SVM model with a non-linear kernel\n",
    "model = SVC(kernel='poly')\n",
    "X_train, X_test, y_train, y_test = train_test_split(selectedFeatures, labels, train_size = 0.5, random_state = RND_SEED, shuffle = True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score is 0.9767641996557659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "plt.plot(fpr,tpr,label=\"ROC CURVE, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "print(f'ROC AUC Score is {auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
